{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Mel Spectrograms\n",
    "The purpose of this notebook is to explore the audio data files using Mel Spectrograms. In my previous effort I have used discrete FFT analysis as training data.\n",
    "\n",
    "This work was inspired by Sercan Ö. Arık and Markus Kliegl et al (2017), \"Convolutional Recurrent Neural Networks for Small-Footprint Keyword Spotting\", *Baidu Silicon Valley Artificial IntelligenceLab,1195 Bordeaux Dr. Sunnyvale, CA 94089*\n",
    "\n",
    "The training and test data is prepared using the method described in the above paper. 40 channel Mel Spectrograms of the 16kHz mono audio files are produced using a 10ms sliding window of size four(4) seconds. In addition, the mel spectrogram is constrained to the frequency range of interest which is above 200 Hz and below 8kHz.\n",
    "\n",
    "The data for each Mel Spectrogram is saved, un-rolled, as a csv row in an ouput file. The file name prefix is the source audio file name. The resulting files are very large, in the order of 10s of GBytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "source_directory = r'/Volumes/ThorsHammer/Data Science/data/audio-recognition/16k/'\n",
    "destination_directory = r'/Volumes/ThorsHammer/Data Science/data/audio-recognition/mel_3.5/'\n",
    "\n",
    "stride = 0.01\n",
    "sample_length = 3.5 #seconds\n",
    "sample_rate = 16000\n",
    "\n",
    "# This following represent the first postive class observation in the data\n",
    "positive_classes = {\n",
    "    '161225-001' : 9541250, # Large file takes too long for me to wait.\n",
    "    '161225-002' : 713600,\n",
    "    '161225-003' : 813800,\n",
    "    '161225-004' : 808700,\n",
    "    '161225-005' : 686400\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161225-000.wav\n",
      "161225-001.wav\n",
      "161225-002.wav\n",
      "161225-003.wav\n",
      "161225-004.wav\n",
      "161225-005.wav\n",
      "161225-006.wav\n"
     ]
    }
   ],
   "source": [
    "# Find the audio wav files in the source folder\n",
    "raw_files = []\n",
    "for file in os.listdir(source_directory):\n",
    "    if file.endswith(\".wav\"):\n",
    "        raw_files.append(file)\n",
    "        print(raw_files[-1])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# prepare the destination directory if not already available\n",
    "if not os.path.exists(destination_directory):\n",
    "    os.makedirs(destination_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the mel spectrograms for the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def calc_mel(x, sr, hop_length):\n",
    "    S = librosa.feature.melspectrogram(x, sr=sr, n_mels=40, fmin=200, fmax=8000, hop_length=hop_length)\n",
    "    # Convert to log scale (dB) using peak power as reference.\n",
    "    log_S = librosa.logamplitude(S, ref_power=np.max)\n",
    "    return log_S\n",
    "\n",
    "def load_file(filename, sample_rate = 16000):\n",
    "    data, sample_rate = librosa.load(filename, sr=sample_rate)\n",
    "    return (data, sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def plot_mel(data, hop_length):\n",
    "    librosa.display.specshow(data, x_axis='time', sr=sample_rate, y_axis='mel', hop_length=hop_length)\n",
    "\n",
    "    # Put a descriptive title on the plot\n",
    "    plt.title('mel power spectrogram')\n",
    "\n",
    "    # draw a color bar\n",
    "    plt.colorbar(format='%+02.0f dB')\n",
    "\n",
    "    # Make the figure layout compact\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def save_mel_data(prefix, data):\n",
    "    '''\n",
    "    Save mel data to disk. Input data is an array of mel 2d matrices.\n",
    "    We need to iterate the array and unroll each matrix to occupy a single row in the output file.\n",
    "    Each matrix has dimensions 40 x 401 (there are 40 mel channels for a 4 sec sample).\n",
    "    '''\n",
    "    data = np.asarray(data)\n",
    "    print('Saving mel data: %s'%prefix)\n",
    "    print(data.shape)\n",
    "    \n",
    "    output_file = '{0}{1}-mel.csv'.format(destination_directory,prefix)\n",
    "    rows = []\n",
    "    for mel in data:\n",
    "        row = mel.flatten() # default row-major\n",
    "        rows.append(row)\n",
    "\n",
    "    np.savetxt(output_file, rows, delimiter=',')\n",
    "\n",
    "    print('Done: %s'%output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161225-000.wav\n",
      "Saving mel data: 161225-000.wav\n",
      "(39088, 40, 351)\n",
      "Done: /Volumes/ThorsHammer/Data Science/data/audio-recognition/mel_3.5/161225-000.wav-mel.csv\n",
      "CPU times: user 1h 40s, sys: 12min 54s, total: 1h 13min 35s\n",
      "Wall time: 42min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for filename in raw_files[:1]:\n",
    "    print(filename)\n",
    "    mel = []\n",
    "    data, sample_rate = load_file(os.path.join(source_directory, filename))\n",
    "    hop_length = int(sample_rate*stride)\n",
    "    # perform mel calculation for each sliding window\n",
    "    for i in np.arange(0,len(data)-(int(sample_length*sample_rate)),(int(stride*sample_rate))):\n",
    "        offset = i\n",
    "        x = data[offset:offset+(int(sample_length*sample_rate))]\n",
    "        log_S = calc_mel(x, sample_rate, hop_length=hop_length)\n",
    "        mel.append(log_S)\n",
    "\n",
    "    save_mel_data(filename, mel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Labels for the Audio Sequences\n",
    "The purpose of this section is to generate the target labels for supervised training. This is somewhat manual and the following procedure was used:\n",
    " - open an audio file in [Audacity](http://www.audacityteam.org)\n",
    " - by visual inspection of the waveform locate the start and end samples of the target sequence (verify selection by playing the audio in that range)\n",
    " - using a window of 3.45 seconds (the width of the target sequence in this case) label the time-correlated mel spectrograph observation as class 1, otherwise class 0.\n",
    "\n",
    "The audio file contents are as follows:\n",
    "\n",
    "** Washing Machine **\n",
    "``` \n",
    "File :161225-000\n",
    "Beep Sequence Count: 0\n",
    "\n",
    "File :161225-001\n",
    "Beep Sequence Count: 1\n",
    "Start Sample: 9541250\n",
    "End Sample:  9596500\n",
    "\n",
    "File :161225-002\n",
    "Beep Sequence Count: 1\n",
    "Start Sample: 713600\n",
    "End Sample:  721360\n",
    "\n",
    "File :161225-003\n",
    "Beep Sequence Count: 1\n",
    "Start Sample: 813800\n",
    "End Sample:  869300\n",
    "\n",
    "File :161225-004\n",
    "Beep Sequence Count: 1\n",
    "Start Sample: 808700\n",
    "End Sample:  864000\n",
    "\n",
    "File :161225-005\n",
    "Beep Sequence Count: 1\n",
    "Start Sample: 686400\n",
    "End Sample:  742000\n",
    "```\n",
    "** Dryer **\n",
    "```\n",
    "File :161225-006\n",
    "Beep Sequence Count: 3\n",
    "Start Sample: 201850\n",
    "End Sample: 262330\n",
    "Start Sample: 1156480\n",
    "End Sample:  1212300\n",
    "Start Sample: 2110750\n",
    "End Sample:  2118300\n",
    "```\n",
    "\n",
    "Based on this data we will create the label vector for each mel spectrogram row. \n",
    "\n",
    "**Note:** we need to take into account the sliding 4 second windows with a stride of 10ms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Determine the observation index for a given sample numer\n",
    "def calc_mel_observation_index(raw_sample_number):\n",
    "    observation_index = int(raw_sample_number / (sample_rate * stride))\n",
    "    return observation_index\n",
    "\n",
    "def file_len(filename):\n",
    "    with open(filename) as f:\n",
    "        for i, l in enumerate(f):\n",
    "            pass\n",
    "    return i + 1\n",
    "\n",
    "def list_all_files(source_directory, truncate_extension=False, extension='.wav'):\n",
    "    # Find the audio wav files in the source folder\n",
    "    raw_files = []\n",
    "    for file in os.listdir(source_directory):\n",
    "        if file.endswith(extension):\n",
    "            if(truncate_extension):\n",
    "                file = file[:file.rfind('.')]\n",
    "            raw_files.append(file)\n",
    "            #print(raw_files[-1])\n",
    "            \n",
    "    return raw_files\n",
    "\n",
    "def save_labels(destination_directory, prefix, labels):\n",
    "    output_file = '{0}{1}-mel-labels.csv'.format(destination_directory,prefix)\n",
    "    np.savetxt(output_file,labels,delimiter=',', fmt='%1i')\n",
    "    print('Done: %s'%output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161225-000 target absent\n",
      "Done: /Volumes/ThorsHammer/Data Science/data/audio-recognition/mel_3.5/161225-000-mel-labels.csv\n",
      "161225-001 contains target\n",
      "Done: /Volumes/ThorsHammer/Data Science/data/audio-recognition/mel_3.5/161225-001-mel-labels.csv\n",
      "161225-002 contains target\n",
      "Done: /Volumes/ThorsHammer/Data Science/data/audio-recognition/mel_3.5/161225-002-mel-labels.csv\n",
      "161225-003 contains target\n",
      "Done: /Volumes/ThorsHammer/Data Science/data/audio-recognition/mel_3.5/161225-003-mel-labels.csv\n",
      "161225-004 contains target\n",
      "Done: /Volumes/ThorsHammer/Data Science/data/audio-recognition/mel_3.5/161225-004-mel-labels.csv\n",
      "161225-005 contains target\n",
      "Done: /Volumes/ThorsHammer/Data Science/data/audio-recognition/mel_3.5/161225-005-mel-labels.csv\n",
      "161225-006 target absent\n",
      "Done: /Volumes/ThorsHammer/Data Science/data/audio-recognition/mel_3.5/161225-006-mel-labels.csv\n",
      "{'161225-006': 15433, '161225-004': 5469, '161225-005': 4734, '161225-002': 4792, '161225-003': 5506, '161225-000': 39088, '161225-001': 60582}\n",
      "CPU times: user 6.48 s, sys: 16.4 s, total: 22.9 s\n",
      "Wall time: 2min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "file_sufix = '.wav-mel.csv'\n",
    "all_files = list_all_files(source_directory, truncate_extension=True)\n",
    "file_len_dict = {}\n",
    "file_label_dict = {}\n",
    "\n",
    "for file in sorted(all_files):\n",
    "    \n",
    "    filename = os.path.join(destination_directory,file+file_sufix)\n",
    "    num_observations = file_len(filename)\n",
    "    file_len_dict[file] = num_observations\n",
    "\n",
    "    labels = np.zeros(num_observations)\n",
    "    \n",
    "    if(file in positive_classes.keys()):\n",
    "        print('%s contains target'%file)\n",
    "        start_sample = positive_classes[file]\n",
    "        target_class_range_start = calc_mel_observation_index(start_sample - (sample_rate * 0.5))\n",
    "        target_class_range_end = calc_mel_observation_index(start_sample + (sample_rate * 0.5))\n",
    "        labels[target_class_range_start:target_class_range_end] = 1\n",
    "        file_label_dict[file] = labels\n",
    "    else:\n",
    "        print('%s target absent'%file)\n",
    "    save_labels(destination_directory, file, labels)\n",
    "\n",
    "print (file_len_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
