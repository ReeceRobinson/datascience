{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Training Notebook using Tensorflow\n",
    "This notebook explores a model architecture ustilsing a Recurrent Neural Network with Gated Recurent Units.\n",
    "\n",
    "A small subset of the training data is used to help ensure faster iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "def normalize(train):\n",
    "    mean, std = train.mean(), train.std()\n",
    "    train = (train - mean) / std\n",
    "    return train, mean, std\n",
    "\n",
    "def normalize_with_paras(test, mean, std):\n",
    "    test = (test - mean) / std\n",
    "    return test\n",
    "\n",
    "def next_batch(data, labels, current_batch, batch_size):\n",
    "    start_idx = current_batch * batch_size\n",
    "    end_idx = (current_batch + 1)*batch_size\n",
    "    current_batch += 1\n",
    "    return (current_batch, data[start_idx:end_idx], labels[start_idx:end_idx] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Data Preparation\n",
    "import numpy as np\n",
    "import os\n",
    "mel_directory = r'/Volumes/ThorsHammer/DataScience/data/audio-recognition/mel_3.5/'\n",
    "X_train_1 = np.load(os.path.join(mel_directory,\"161225-002.wav-mel.npy\")).astype(float).transpose(0,2,1)\n",
    "y_train_1 = np.load(os.path.join(mel_directory,\"161225-002-mel-labels.npy\")).astype(int) #.reshape((-1,1))\n",
    "X_train_2 = np.load(os.path.join(mel_directory,\"161225-004.wav-mel.npy\")).astype(float).transpose(0,2,1)\n",
    "y_train_2 = np.load(os.path.join(mel_directory,\"161225-004-mel-labels.npy\")).astype(int) #.reshape((-1,1))\n",
    "\n",
    "X_train = np.vstack((X_train_1, X_train_2))\n",
    "y_train = np.concatenate((y_train_1,y_train_2), axis=0)\n",
    "\n",
    "X_test = np.load(os.path.join(mel_directory,\"161225-003.wav-mel.npy\")).astype(float).transpose(0,2,1)\n",
    "y_test = np.load(os.path.join(mel_directory,\"161225-003-mel-labels.npy\")).astype(int) #.reshape((-1,1))\n",
    "X_train, mean, std = normalize(X_train)\n",
    "X_test = normalize_with_paras(X_test, mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('training data shape:', (10261, 351, 40))\n",
      "('training labels shape:', (10261,))\n",
      "('test data shape:', (5506, 351, 40))\n",
      "('test labels shape:', (5506,))\n"
     ]
    }
   ],
   "source": [
    "print('training data shape:',X_train.shape)\n",
    "print('training labels shape:',y_train.shape)\n",
    "print('test data shape:',X_test.shape)\n",
    "print('test labels shape:',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 98.18. This is achieved by choosing the majority class.\n"
     ]
    }
   ],
   "source": [
    "# Baseline accuracy i.e. always choose the most frequent class\n",
    "baseline_acc = 100-(100.0*np.sum(y_test)/y_test.shape[0])\n",
    "print('Baseline accuracy: %0.2f. This is achieved by choosing the majority class.'%baseline_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Construction\n",
    "The following model is a Recurrent Neural Network (RNN) with Gated Recurrent Units (GRU) memory cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import fully_connected\n",
    "from tensorflow.contrib.rnn import GRUCell\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir_train = \"{}/run-{}-train/\".format(root_logdir, now)\n",
    "logdir_test = \"{}/run-{}-test/\".format(root_logdir, now)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "n_inputs = 40\n",
    "n_steps = 351\n",
    "\n",
    "n_neurons = 32\n",
    "n_layers = 2\n",
    "n_fully_connected = 64\n",
    "n_outputs = 2\n",
    "\n",
    "learning_rate = 0.001\n",
    "keep_prob = 0.5\n",
    "\n",
    "epsilon = 0.00000001\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs]) # n_steps is the number of time steps\n",
    "y = tf.placeholder(tf.int64, [None])\n",
    "\n",
    "# RNN(GRU) & fully connected layers\n",
    "with tf.name_scope('rnn'):\n",
    "    with tf.contrib.framework.arg_scope(\n",
    "        [ fully_connected],\n",
    "        weights_initializer = tf.contrib.layers.variance_scaling_initializer()):\n",
    "        \n",
    "        cells=[]\n",
    "        for _ in range(n_layers):\n",
    "            cell = tf.contrib.rnn.DropoutWrapper(GRUCell(num_units=n_neurons), input_keep_prob=keep_prob)\n",
    "            cells.append(cell)\n",
    "        multi_layer_cell = tf.contrib.rnn.MultiRNNCell(cells, state_is_tuple=False)        \n",
    "        outputs, states = tf.nn.dynamic_rnn(multi_layer_cell, X, dtype=tf.float32)\n",
    "        FC_1_logits = fully_connected(states, n_fully_connected)\n",
    "        logits = fully_connected(FC_1_logits, n_outputs, activation_fn=None)\n",
    "\n",
    "# cost function\n",
    "with tf.name_scope('loss'):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "\n",
    "# Gradient decent optimiser\n",
    "with tf.name_scope('train'):    \n",
    "    optimiser = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    training_op = optimiser.minimize(loss)\n",
    "\n",
    "# evaluation using accuracy\n",
    "with tf.name_scope('eval'):\n",
    "    proba = tf.nn.softmax(logits, name='proba')\n",
    "    predicted = tf.arg_max(proba,1)\n",
    "    confusion = tf.confusion_matrix(labels=y, predictions=predicted)\n",
    "\n",
    "    actual = y\n",
    "\n",
    "    tp = tf.to_float(tf.count_nonzero(predicted * actual))\n",
    "    tn = tf.to_float(tf.count_nonzero((predicted - 1) * (actual - 1)))\n",
    "    fp = tf.to_float(tf.count_nonzero(predicted * (actual - 1)))\n",
    "    fn = tf.to_float(tf.count_nonzero((predicted - 1) * actual))\n",
    "    \n",
    "    precision = tp /(tp + fp + epsilon)\n",
    "    recall = tp / (tp + fn + epsilon)\n",
    "    f1 = 2 * precision * recall / (precision + recall + epsilon)\n",
    "    \n",
    "    precision_summary = tf.summary.scalar('precision',precision)\n",
    "    recall_summary = tf.summary.scalar('recall',recall)\n",
    "    f1_summary = tf.summary.scalar('f1',f1)\n",
    "    \n",
    "    tp_summary = tf.summary.scalar('tp',tp)\n",
    "    fp_summary = tf.summary.scalar('fp',fp)\n",
    "\n",
    "    tn_summary = tf.summary.scalar('tn',tn)\n",
    "    fn_summary = tf.summary.scalar('fn',fn)\n",
    "\n",
    "    # Merge all the summaries and write them out to /tmp/mnist_logs (by default)\n",
    "    merged = tf.summary.merge_all()\n",
    "    file_writer_train = tf.summary.FileWriter(logdir_train, tf.get_default_graph()) \n",
    "    file_writer_test = tf.summary.FileWriter(logdir_test, tf.get_default_graph()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'f1 test score:', 0.0)\n",
      "Train Confusion Matrix:\n",
      "[[10061     0]\n",
      " [  200     0]]\n",
      "Test Confusion Matrix:\n",
      "[[5406    0]\n",
      " [ 100    0]]\n",
      "(1, 'f1 test score:', 0.0)\n",
      "Train Confusion Matrix:\n",
      "[[10061     0]\n",
      " [  200     0]]\n",
      "Test Confusion Matrix:\n",
      "[[5406    0]\n",
      " [ 100    0]]\n",
      "(2, 'f1 test score:', 0.0)\n",
      "Train Confusion Matrix:\n",
      "[[10061     0]\n",
      " [  200     0]]\n",
      "Test Confusion Matrix:\n",
      "[[5406    0]\n",
      " [ 100    0]]\n",
      "(3, 'f1 test score:', 0.0)\n",
      "Train Confusion Matrix:\n",
      "[[10061     0]\n",
      " [  200     0]]\n",
      "Test Confusion Matrix:\n",
      "[[5406    0]\n",
      " [ 100    0]]\n",
      "(4, 'f1 test score:', 0.0)\n",
      "Train Confusion Matrix:\n",
      "[[10061     0]\n",
      " [  200     0]]\n",
      "Test Confusion Matrix:\n",
      "[[5406    0]\n",
      " [ 100    0]]\n",
      "(5, 'f1 test score:', 0.0)\n",
      "Train Confusion Matrix:\n",
      "[[10061     0]\n",
      " [  200     0]]\n",
      "Test Confusion Matrix:\n",
      "[[5406    0]\n",
      " [ 100    0]]\n",
      "(6, 'f1 test score:', 0.0)\n",
      "Train Confusion Matrix:\n",
      "[[10061     0]\n",
      " [  200     0]]\n",
      "Test Confusion Matrix:\n",
      "[[5406    0]\n",
      " [ 100    0]]\n",
      "(7, 'f1 test score:', 0.0)\n",
      "Train Confusion Matrix:\n",
      "[[10061     0]\n",
      " [  200     0]]\n",
      "Test Confusion Matrix:\n",
      "[[5406    0]\n",
      " [ 100    0]]\n",
      "(8, 'f1 test score:', 0.0)\n",
      "Train Confusion Matrix:\n",
      "[[10061     0]\n",
      " [  200     0]]\n",
      "Test Confusion Matrix:\n",
      "[[5406    0]\n",
      " [ 100    0]]\n",
      "(9, 'f1 test score:', 0.0)\n",
      "Train Confusion Matrix:\n",
      "[[10061     0]\n",
      " [  200     0]]\n",
      "Test Confusion Matrix:\n",
      "[[5406    0]\n",
      " [ 100    0]]\n",
      "(10, 'f1 test score:', 0.074766345)\n",
      "Train Confusion Matrix:\n",
      "[[10055     6]\n",
      " [  172    28]]\n",
      "Test Confusion Matrix:\n",
      "[[5404    2]\n",
      " [  95    5]]\n",
      "(11, 'f1 test score:', 0.0)\n",
      "Train Confusion Matrix:\n",
      "[[10061     0]\n",
      " [  200     0]]\n",
      "Test Confusion Matrix:\n",
      "[[5406    0]\n",
      " [ 100    0]]\n",
      "(12, 'f1 test score:', 0.0)\n",
      "Train Confusion Matrix:\n",
      "[[10061     0]\n",
      " [  200     0]]\n",
      "Test Confusion Matrix:\n",
      "[[5406    0]\n",
      " [ 100    0]]\n",
      "(13, 'f1 test score:', 0.0)\n",
      "Train Confusion Matrix:\n",
      "[[10061     0]\n",
      " [  200     0]]\n",
      "Test Confusion Matrix:\n",
      "[[5406    0]\n",
      " [ 100    0]]\n",
      "(14, 'f1 test score:', 0.058252428)\n",
      "Train Confusion Matrix:\n",
      "[[10053     8]\n",
      " [  170    30]]\n",
      "Test Confusion Matrix:\n",
      "[[5406    0]\n",
      " [  98    2]]\n",
      "(15, 'f1 test score:', 0.0)\n",
      "Train Confusion Matrix:\n",
      "[[10061     0]\n",
      " [  200     0]]\n",
      "Test Confusion Matrix:\n",
      "[[5406    0]\n",
      " [ 100    0]]\n",
      "(16, 'f1 test score:', 0.0)\n",
      "Train Confusion Matrix:\n",
      "[[10061     0]\n",
      " [  200     0]]\n",
      "Test Confusion Matrix:\n",
      "[[5406    0]\n",
      " [ 100    0]]\n",
      "(17, 'f1 test score:', 0.1754386)\n",
      "Train Confusion Matrix:\n",
      "[[10049    12]\n",
      " [   65   135]]\n",
      "Test Confusion Matrix:\n",
      "[[5400    6]\n",
      " [  90   10]]\n",
      "(18, 'f1 test score:', 0.0)\n",
      "Train Confusion Matrix:\n",
      "[[10061     0]\n",
      " [  200     0]]\n",
      "Test Confusion Matrix:\n",
      "[[5406    0]\n",
      " [ 100    0]]\n",
      "(19, 'f1 test score:', 0.0)\n",
      "Train Confusion Matrix:\n",
      "[[10061     0]\n",
      " [  117    83]]\n",
      "Test Confusion Matrix:\n",
      "[[5406    0]\n",
      " [ 100    0]]\n",
      "(20, 'f1 test score:', 0.17721519)\n",
      "Train Confusion Matrix:\n",
      "[[10016    45]\n",
      " [  191     9]]\n",
      "Test Confusion Matrix:\n",
      "[[5366   40]\n",
      " [  84   16]]\n",
      "(21, 'f1 test score:', 0.0)\n",
      "Train Confusion Matrix:\n",
      "[[10061     0]\n",
      " [  200     0]]\n",
      "Test Confusion Matrix:\n",
      "[[5406    0]\n",
      " [ 100    0]]\n",
      "(22, 'f1 test score:', 0.0)\n",
      "Train Confusion Matrix:\n",
      "[[10061     0]\n",
      " [  200     0]]\n",
      "Test Confusion Matrix:\n",
      "[[5406    0]\n",
      " [ 100    0]]\n",
      "(23, 'f1 test score:', 0.0)\n",
      "Train Confusion Matrix:\n",
      "[[10061     0]\n",
      " [  200     0]]\n",
      "Test Confusion Matrix:\n",
      "[[5406    0]\n",
      " [ 100    0]]\n",
      "(24, 'f1 test score:', 0.0)\n",
      "Train Confusion Matrix:\n",
      "[[10061     0]\n",
      " [  200     0]]\n",
      "Test Confusion Matrix:\n",
      "[[5405    1]\n",
      " [ 100    0]]\n",
      "(25, 'f1 test score:', 0.34074074)\n",
      "Train Confusion Matrix:\n",
      "[[10060     1]\n",
      " [  172    28]]\n",
      "Test Confusion Matrix:\n",
      "[[5395   11]\n",
      " [  81   19]]\n",
      "(26, 'f1 test score:', 0.01980198)\n",
      "Train Confusion Matrix:\n",
      "[[10061     0]\n",
      " [  200     0]]\n",
      "Test Confusion Matrix:\n",
      "[[5406    0]\n",
      " [ 100    0]]\n",
      "(27, 'f1 test score:', 0.0)\n",
      "Train Confusion Matrix:\n",
      "[[10061     0]\n",
      " [  195     5]]\n",
      "Test Confusion Matrix:\n",
      "[[5406    0]\n",
      " [  99    1]]\n",
      "(28, 'f1 test score:', 0.59060401)\n",
      "Train Confusion Matrix:\n",
      "[[10008    53]\n",
      " [   11   189]]\n",
      "Test Confusion Matrix:\n",
      "[[5404    2]\n",
      " [  54   46]]\n",
      "(29, 'f1 test score:', 0.26086959)\n",
      "Train Confusion Matrix:\n",
      "[[10061     0]\n",
      " [   92   108]]\n",
      "Test Confusion Matrix:\n",
      "[[5406    0]\n",
      " [  86   14]]\n",
      "(30, 'f1 test score:', 0.40909094)\n",
      "Train Confusion Matrix:\n",
      "[[9945  116]\n",
      " [   6  194]]\n",
      "Test Confusion Matrix:\n",
      "[[5399    7]\n",
      " [  75   25]]\n",
      "(31, 'f1 test score:', 0.31666666)\n",
      "Train Confusion Matrix:\n",
      "[[10060     1]\n",
      " [   65   135]]\n",
      "Test Confusion Matrix:\n",
      "[[5406    0]\n",
      " [  80   20]]\n",
      "(32, 'f1 test score:', 0.43609023)\n",
      "Train Confusion Matrix:\n",
      "[[10060     1]\n",
      " [   24   176]]\n",
      "Test Confusion Matrix:\n",
      "[[5404    2]\n",
      " [  65   35]]\n",
      "(33, 'f1 test score:', 0.11320755)\n",
      "Train Confusion Matrix:\n",
      "[[10061     0]\n",
      " [   66   134]]\n",
      "Test Confusion Matrix:\n",
      "[[5406    0]\n",
      " [  88   12]]\n",
      "(34, 'f1 test score:', 0.0)\n",
      "Train Confusion Matrix:\n",
      "[[10061     0]\n",
      " [   54   146]]\n",
      "Test Confusion Matrix:\n",
      "[[5406    0]\n",
      " [ 100    0]]\n",
      "(35, 'f1 test score:', 0.039215688)\n",
      "Train Confusion Matrix:\n",
      "[[10049    12]\n",
      " [   19   181]]\n",
      "Test Confusion Matrix:\n",
      "[[5406    0]\n",
      " [  98    2]]\n",
      "(36, 'f1 test score:', 0.6875)\n",
      "Train Confusion Matrix:\n",
      "[[9987   74]\n",
      " [   5  195]]\n",
      "Test Confusion Matrix:\n",
      "[[5324   82]\n",
      " [   0  100]]\n",
      "(37, 'f1 test score:', 0.30508474)\n",
      "Train Confusion Matrix:\n",
      "[[10046    15]\n",
      " [   48   152]]\n",
      "Test Confusion Matrix:\n",
      "[[5406    0]\n",
      " [  83   17]]\n",
      "(38, 'f1 test score:', 0.82872921)\n",
      "Train Confusion Matrix:\n",
      "[[10061     0]\n",
      " [   37   163]]\n",
      "Test Confusion Matrix:\n",
      "[[5397    9]\n",
      " [  21   79]]\n",
      "(39, 'f1 test score:', 0.89947093)\n",
      "Train Confusion Matrix:\n",
      "[[10060     1]\n",
      " [   20   180]]\n",
      "Test Confusion Matrix:\n",
      "[[5401    5]\n",
      " [  16   84]]\n",
      "(40, 'f1 test score:', 0.90217388)\n",
      "Train Confusion Matrix:\n",
      "[[10060     1]\n",
      " [   25   175]]\n",
      "Test Confusion Matrix:\n",
      "[[5405    1]\n",
      " [  21   79]]\n",
      "(41, 'f1 test score:', 0.31932771)\n",
      "Train Confusion Matrix:\n",
      "[[10061     0]\n",
      " [   70   130]]\n",
      "Test Confusion Matrix:\n",
      "[[5406    0]\n",
      " [  88   12]]\n",
      "(42, 'f1 test score:', 0.87150836)\n",
      "Train Confusion Matrix:\n",
      "[[10060     1]\n",
      " [   12   188]]\n",
      "Test Confusion Matrix:\n",
      "[[5404    2]\n",
      " [  28   72]]\n",
      "(43, 'f1 test score:', 0.863388)\n",
      "Train Confusion Matrix:\n",
      "[[10060     1]\n",
      " [   12   188]]\n",
      "Test Confusion Matrix:\n",
      "[[5399    7]\n",
      " [  17   83]]\n",
      "(44, 'f1 test score:', 0.85067874)\n",
      "Train Confusion Matrix:\n",
      "[[10057     4]\n",
      " [    1   199]]\n",
      "Test Confusion Matrix:\n",
      "[[5375   31]\n",
      " [   6   94]]\n",
      "(45, 'f1 test score:', 0.7863248)\n",
      "Train Confusion Matrix:\n",
      "[[10055     6]\n",
      " [    6   194]]\n",
      "Test Confusion Matrix:\n",
      "[[5364   42]\n",
      " [   7   93]]\n",
      "(46, 'f1 test score:', 0.8125)\n",
      "Train Confusion Matrix:\n",
      "[[10059     2]\n",
      " [   10   190]]\n",
      "Test Confusion Matrix:\n",
      "[[5367   39]\n",
      " [   5   95]]\n",
      "(47, 'f1 test score:', 0.78313249)\n",
      "Train Confusion Matrix:\n",
      "[[10061     0]\n",
      " [   29   171]]\n",
      "Test Confusion Matrix:\n",
      "[[5404    2]\n",
      " [  32   68]]\n",
      "(48, 'f1 test score:', 0.0)\n",
      "Train Confusion Matrix:\n",
      "[[10061     0]\n",
      " [   35   165]]\n",
      "Test Confusion Matrix:\n",
      "[[5406    0]\n",
      " [ 100    0]]\n",
      "(49, 'f1 test score:', 0.31932771)\n",
      "Train Confusion Matrix:\n",
      "[[10048    13]\n",
      " [   19   181]]\n",
      "Test Confusion Matrix:\n",
      "[[5406    0]\n",
      " [  84   16]]\n",
      "(50, 'f1 test score:', 0.86033517)\n",
      "Train Confusion Matrix:\n",
      "[[10059     2]\n",
      " [    7   193]]\n",
      "Test Confusion Matrix:\n",
      "[[5404    2]\n",
      " [  27   73]]\n",
      "(51, 'f1 test score:', 0.84324324)\n",
      "Train Confusion Matrix:\n",
      "[[10057     4]\n",
      " [    7   193]]\n",
      "Test Confusion Matrix:\n",
      "[[5400    6]\n",
      " [  19   81]]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 154\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    best_f1 = -1\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        current_batch = 0\n",
    "        for iteration in range(X_train.shape[0] // batch_size):\n",
    "            current_batch, X_batch, y_batch = next_batch(X_train, y_train, current_batch, batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "\n",
    "        # Compute epoch metrics of interest to display in Tensorboard\n",
    "        summary_train = sess.run(merged, {X: X_train, y: y_train})\n",
    "        file_writer_train.add_summary(summary_train,epoch)\n",
    "        file_writer_train.flush()\n",
    "        \n",
    "        summary_test = sess.run(merged, {X: X_test, y: y_test})\n",
    "        file_writer_test.add_summary(summary_test,epoch)\n",
    "        file_writer_test.flush()   \n",
    "        \n",
    "        # Compute epoch metrics of interest to print in this notebook \n",
    "        pred_train = predicted.eval(feed_dict={X: X_train, y: y_train})\n",
    "        pred_test = predicted.eval(feed_dict={X: X_test, y: y_test})\n",
    "        \n",
    "        logits_train_vals = logits.eval(feed_dict={X: X_train, y: y_train})\n",
    "        logits_test_vals = logits.eval(feed_dict={X: X_test, y: y_test})\n",
    "        confusion_train = confusion.eval(feed_dict={logits: logits_train_vals, y: y_train})\n",
    "        confusion_test = confusion.eval(feed_dict={logits: logits_test_vals, y: y_test})\n",
    "        \n",
    "        tp_val_test = tp.eval(feed_dict={predicted:pred_test, actual:y_test})\n",
    "        tn_val_test = tn.eval(feed_dict={predicted:pred_test, actual:y_test})\n",
    "        fp_val_test = fp.eval(feed_dict={predicted:pred_test, actual:y_test})\n",
    "        fn_val_test = fn.eval(feed_dict={predicted:pred_test, actual:y_test})\n",
    "        prec_val_test = precision.eval(feed_dict={tp:tp_val_test,fp:fp_val_test})\n",
    "        rec_val_test = recall.eval(feed_dict={tp:tp_val_test,fn:fn_val_test})\n",
    "        f1_score_test = f1.eval(feed_dict={precision:prec_val_test, recall:rec_val_test})\n",
    "              \n",
    "        print(epoch, \"f1 test score:\",f1_score_test)\n",
    "        print(\"Train Confusion Matrix:\")\n",
    "        print(confusion_train)\n",
    "        print(\"Test Confusion Matrix:\")\n",
    "        print(confusion_test)\n",
    "\n",
    "        # Save best model so far\n",
    "        if f1_score_test > best_f1:\n",
    "            save_path = saver.save(sess, './my_model_final.ckpt')\n",
    "            best_f1 = f1_score_test\n",
    "            \n",
    "    file_writer_train.close()\n",
    "    file_writer_test.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging\n",
    "The following cell provides debug information from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    logits_vals = logits.eval(feed_dict={X:X_train[4500:4600],y:y_train[4500:4600]})\n",
    "    y_vals = y.eval(feed_dict={y: y_train[4500:4600]})\n",
    "    pred = predicted.eval(feed_dict={X:X_train[4500:4600],y:y_train[4500:4600]})\n",
    "    tp_val = tp.eval(feed_dict={predicted:pred, actual:y_vals})\n",
    "    tn_val = tn.eval(feed_dict={predicted:pred, actual:y_vals})\n",
    "    fp_val = fp.eval(feed_dict={predicted:pred, actual:y_vals})\n",
    "    fn_val = fn.eval(feed_dict={predicted:pred, actual:y_vals})\n",
    "    confus = confusion.eval(feed_dict={logits:logits_vals, y: y_vals})\n",
    "    prec_val = precision.eval(feed_dict={tp:tp_val,fp:fp_val})\n",
    "    rec_val = recall.eval(feed_dict={tp:tp_val,fn:fn_val})\n",
    "    f1_score = f1.eval(feed_dict={precision:prec_val, recall:rec_val})\n",
    "    print(y_vals)\n",
    "    print(pred)\n",
    "    print(tp_val)\n",
    "    print(tn_val)\n",
    "    print(fp_val)\n",
    "    print(fn_val)\n",
    "    print(confus)\n",
    "    print(prec_val)\n",
    "    print(rec_val)\n",
    "    print(f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate a Prediction from a Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# look at an example input\n",
    "from matplotlib import pyplot as plt\n",
    "i = 5100\n",
    "plt.imshow(X_test[i], cmap=plt.cm.magma)\n",
    "plt.show()\n",
    "print('Label:',y_test[i])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "    pred = predicted.eval(feed_dict={X:X_test[i].reshape(1,n_steps,n_inputs)})\n",
    "    print('prediction: %i'%pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# TODOs\n",
    "* Hyper parameter tuning\n",
    "* More test data\n",
    "* Augment data with copies of beeps"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
