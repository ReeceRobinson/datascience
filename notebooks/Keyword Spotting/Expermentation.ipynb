{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Training Notebook using Tensorflow\n",
    "This notebook explores a model architecture ustilsing a Recurrent Neural Network with Gated Recurent Units.\n",
    "\n",
    "A small subset of the training data is used to help ensure faster iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import errno    \n",
    "import os\n",
    "\n",
    "# Helper Functions\n",
    "def normalize(train):\n",
    "    mean, std = train.mean(), train.std()\n",
    "    train = (train - mean) / std\n",
    "    print(\"mean: %f\"%mean)\n",
    "    print(\"std: %f\"%std)\n",
    "    return train, mean, std\n",
    "\n",
    "def normalize_with_paras(test, mean, std):\n",
    "    test = (test - mean) / std\n",
    "    return test\n",
    "\n",
    "def next_batch(data, labels, current_batch, batch_size):\n",
    "    start_idx = current_batch * batch_size\n",
    "    end_idx = (current_batch + 1)*batch_size\n",
    "    current_batch += 1\n",
    "    return (current_batch, data[start_idx:end_idx], labels[start_idx:end_idx] )\n",
    "\n",
    "def makedirs(path):\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError as exc:  # Python >2.5\n",
    "        if exc.errno == errno.EEXIST and os.path.isdir(path):\n",
    "            pass\n",
    "        else:\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: -31.797126\n",
      "std: 14.150785\n"
     ]
    }
   ],
   "source": [
    "# Data Preparation\n",
    "import numpy as np\n",
    "import os\n",
    "mel_directory = r'/Volumes/ThorsHammer/DataScience/data/audio-recognition/mel_3.5/'\n",
    "# X_train_1 = np.load(os.path.join(mel_directory,\"161225-001.wav-mel.npy\")).astype(float).transpose(0,2,1)\n",
    "# y_train_1 = np.load(os.path.join(mel_directory,\"161225-001-mel-labels.npy\")).astype(int)\n",
    "X_train_2 = np.load(os.path.join(mel_directory,\"161225-002.wav-mel.npy\")).astype(float).transpose(0,2,1)\n",
    "y_train_2 = np.load(os.path.join(mel_directory,\"161225-002-mel-labels.npy\")).astype(int)\n",
    "X_train_4 = np.load(os.path.join(mel_directory,\"161225-004.wav-mel.npy\")).astype(float).transpose(0,2,1)\n",
    "y_train_4 = np.load(os.path.join(mel_directory,\"161225-004-mel-labels.npy\")).astype(int)\n",
    "\n",
    "# X_train_part = np.vstack((X_train_1, X_train_2))\n",
    "X_train = np.vstack((X_train_2, X_train_4))\n",
    "\n",
    "# del(X_train_1)\n",
    "del(X_train_2)\n",
    "del(X_train_4)\n",
    "# del(X_train_part)\n",
    "\n",
    "# y_train_part = np.concatenate((y_train_1,y_train_2), axis=0)\n",
    "y_train = np.concatenate((y_train_2,y_train_4), axis=0)\n",
    "\n",
    "# del(y_train_1)\n",
    "del(y_train_2)\n",
    "del(y_train_4)\n",
    "# del(y_train_part)\n",
    "\n",
    "X_test = np.load(os.path.join(mel_directory,\"161225-003.wav-mel.npy\")).astype(float).transpose(0,2,1)\n",
    "y_test = np.load(os.path.join(mel_directory,\"161225-003-mel-labels.npy\")).astype(int)\n",
    "X_train, mean, std = normalize(X_train)\n",
    "X_test = normalize_with_paras(X_test, mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('training data shape:', (10261, 351, 40))\n",
      "('training labels shape:', (10261,))\n",
      "('test data shape:', (5506, 351, 40))\n",
      "('test labels shape:', (5506,))\n"
     ]
    }
   ],
   "source": [
    "print('training data shape:',X_train.shape)\n",
    "print('training labels shape:',y_train.shape)\n",
    "print('test data shape:',X_test.shape)\n",
    "print('test labels shape:',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 98.18. This is achieved by choosing the majority class.\n"
     ]
    }
   ],
   "source": [
    "# Baseline accuracy i.e. always choose the most frequent class\n",
    "baseline_acc = 100-(100.0*np.sum(y_test)/y_test.shape[0])\n",
    "print('Baseline accuracy: %0.2f. This is achieved by choosing the majority class.'%baseline_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Model Construction\n",
    "The following model is a Recurrent Neural Network (RNN) with Gated Recurrent Units (GRU) memory cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import fully_connected\n",
    "from tensorflow.contrib.rnn import GRUCell\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir_train = \"{}/run-{}-train/\".format(root_logdir, now)\n",
    "logdir_test = \"{}/run-{}-test/\".format(root_logdir, now)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "n_inputs = 40\n",
    "n_steps = 351\n",
    "\n",
    "n_neurons = 32\n",
    "n_layers = 2\n",
    "n_fully_connected = 64\n",
    "n_outputs = 2\n",
    "\n",
    "learning_rate = 0.001\n",
    "keep_prob = 0.5\n",
    "\n",
    "epsilon = 0.00000001\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs]) # n_steps is the number of time steps\n",
    "y = tf.placeholder(tf.int64, [None])\n",
    "\n",
    "# RNN(GRU) & fully connected layers\n",
    "with tf.name_scope('rnn'):\n",
    "    with tf.contrib.framework.arg_scope(\n",
    "        [ fully_connected],\n",
    "        weights_initializer = tf.contrib.layers.variance_scaling_initializer()):\n",
    "        \n",
    "        cells=[]\n",
    "        for _ in range(n_layers):\n",
    "            cell = tf.contrib.rnn.DropoutWrapper(GRUCell(num_units=n_neurons), input_keep_prob=keep_prob)\n",
    "            cells.append(cell)\n",
    "        multi_layer_cell = tf.contrib.rnn.MultiRNNCell(cells, state_is_tuple=False)        \n",
    "        outputs, states = tf.nn.dynamic_rnn(multi_layer_cell, X, dtype=tf.float32)\n",
    "        FC_1_logits = fully_connected(states, n_fully_connected)\n",
    "        logits = fully_connected(FC_1_logits, n_outputs, activation_fn=None)\n",
    "\n",
    "# cost function\n",
    "with tf.name_scope('loss'):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "\n",
    "# Gradient decent optimiser\n",
    "with tf.name_scope('train'):    \n",
    "    optimiser = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    training_op = optimiser.minimize(loss)\n",
    "\n",
    "# evaluation using accuracy\n",
    "with tf.name_scope('eval'):\n",
    "    proba = tf.nn.softmax(logits, name='proba')\n",
    "    predicted = tf.arg_max(proba,1)\n",
    "    confusion = tf.confusion_matrix(labels=y, predictions=predicted)\n",
    "\n",
    "    actual = y\n",
    "\n",
    "    tp = tf.to_float(tf.count_nonzero(predicted * actual))\n",
    "    tn = tf.to_float(tf.count_nonzero((predicted - 1) * (actual - 1)))\n",
    "    fp = tf.to_float(tf.count_nonzero(predicted * (actual - 1)))\n",
    "    fn = tf.to_float(tf.count_nonzero((predicted - 1) * actual))\n",
    "    \n",
    "    precision = tp /(tp + fp + epsilon)\n",
    "    recall = tp / (tp + fn + epsilon)\n",
    "    f1 = 2 * precision * recall / (precision + recall + epsilon)\n",
    "    \n",
    "    precision_summary = tf.summary.scalar('precision',precision)\n",
    "    recall_summary = tf.summary.scalar('recall',recall)\n",
    "    f1_summary = tf.summary.scalar('f1',f1)\n",
    "    \n",
    "    tp_summary = tf.summary.scalar('tp',tp)\n",
    "    fp_summary = tf.summary.scalar('fp',fp)\n",
    "\n",
    "    tn_summary = tf.summary.scalar('tn',tn)\n",
    "    fn_summary = tf.summary.scalar('fn',fn)\n",
    "\n",
    "    # Merge all the summaries and write them out to /tmp/mnist_logs (by default)\n",
    "    merged = tf.summary.merge_all()\n",
    "    file_writer_train = tf.summary.FileWriter(logdir_train, tf.get_default_graph()) \n",
    "    file_writer_test = tf.summary.FileWriter(logdir_test, tf.get_default_graph()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Model Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'f1 test score:', 0.0)\n",
      "Train Confusion Matrix:\n",
      "[[10060     1]\n",
      " [  200     0]]\n",
      "Test Confusion Matrix:\n",
      "[[5406    0]\n",
      " [ 100    0]]\n",
      "(1, 'f1 test score:', 0.0)\n",
      "Train Confusion Matrix:\n",
      "[[10058     3]\n",
      " [  199     1]]\n",
      "Test Confusion Matrix:\n",
      "[[5406    0]\n",
      " [ 100    0]]\n",
      "(2, 'f1 test score:', 0.0)\n",
      "Train Confusion Matrix:\n",
      "[[10060     1]\n",
      " [  200     0]]\n",
      "Test Confusion Matrix:\n",
      "[[5406    0]\n",
      " [ 100    0]]\n",
      "(3, 'f1 test score:', 0.0)\n",
      "Train Confusion Matrix:\n",
      "[[10061     0]\n",
      " [  199     1]]\n",
      "Test Confusion Matrix:\n",
      "[[5406    0]\n",
      " [ 100    0]]\n",
      "(4, 'f1 test score:', 0.0)\n",
      "Train Confusion Matrix:\n",
      "[[10061     0]\n",
      " [  200     0]]\n",
      "Test Confusion Matrix:\n",
      "[[5406    0]\n",
      " [ 100    0]]\n",
      "(5, 'f1 test score:', 0.0)\n",
      "Train Confusion Matrix:\n",
      "[[10060     1]\n",
      " [  200     0]]\n",
      "Test Confusion Matrix:\n",
      "[[5406    0]\n",
      " [ 100    0]]\n",
      "(6, 'f1 test score:', 0.039215688)\n",
      "Train Confusion Matrix:\n",
      "[[10048    13]\n",
      " [  177    23]]\n",
      "Test Confusion Matrix:\n",
      "[[5406    0]\n",
      " [  97    3]]\n",
      "Saved new best model with f1 score: 0.0392\n",
      "(7, 'f1 test score:', 0.28571427)\n",
      "Train Confusion Matrix:\n",
      "[[10000    61]\n",
      " [  109    91]]\n",
      "Test Confusion Matrix:\n",
      "[[5406    0]\n",
      " [  80   20]]\n",
      "Saved new best model with f1 score: 0.2857\n",
      "(8, 'f1 test score:', 0.0)\n",
      "Train Confusion Matrix:\n",
      "[[10061     0]\n",
      " [  200     0]]\n",
      "Test Confusion Matrix:\n",
      "[[5406    0]\n",
      " [ 100    0]]\n",
      "(9, 'f1 test score:', 0.0)\n",
      "Train Confusion Matrix:\n",
      "[[10061     0]\n",
      " [  200     0]]\n",
      "Test Confusion Matrix:\n",
      "[[5406    0]\n",
      " [ 100    0]]\n",
      "(10, 'f1 test score:', 0.0)\n",
      "Train Confusion Matrix:\n",
      "[[10060     1]\n",
      " [  200     0]]\n",
      "Test Confusion Matrix:\n",
      "[[5406    0]\n",
      " [ 100    0]]\n",
      "(11, 'f1 test score:', 0.039215688)\n",
      "Train Confusion Matrix:\n",
      "[[10061     0]\n",
      " [  196     4]]\n",
      "Test Confusion Matrix:\n",
      "[[5405    1]\n",
      " [  99    1]]\n",
      "(12, 'f1 test score:', 0.12727273)\n",
      "Train Confusion Matrix:\n",
      "[[10036    25]\n",
      " [  160    40]]\n",
      "Test Confusion Matrix:\n",
      "[[5405    1]\n",
      " [  93    7]]\n",
      "(13, 'f1 test score:', 0.146789)\n",
      "Train Confusion Matrix:\n",
      "[[10061     0]\n",
      " [  198     2]]\n",
      "Test Confusion Matrix:\n",
      "[[5402    4]\n",
      " [  94    6]]\n",
      "(14, 'f1 test score:', 0.0)\n",
      "Train Confusion Matrix:\n",
      "[[10061     0]\n",
      " [  200     0]]\n",
      "Test Confusion Matrix:\n",
      "[[5406    0]\n",
      " [ 100    0]]\n",
      "(15, 'f1 test score:', 0.058252428)\n",
      "Train Confusion Matrix:\n",
      "[[10061     0]\n",
      " [  198     2]]\n",
      "Test Confusion Matrix:\n",
      "[[5406    0]\n",
      " [  95    5]]\n",
      "(16, 'f1 test score:', 0.3611111)\n",
      "Train Confusion Matrix:\n",
      "[[10047    14]\n",
      " [  150    50]]\n",
      "Test Confusion Matrix:\n",
      "[[5387   19]\n",
      " [  71   29]]\n",
      "Saved new best model with f1 score: 0.3611\n",
      "(17, 'f1 test score:', 0.40740743)\n",
      "Train Confusion Matrix:\n",
      "[[10059     2]\n",
      " [  156    44]]\n",
      "Test Confusion Matrix:\n",
      "[[5374   32]\n",
      " [  66   34]]\n",
      "Saved new best model with f1 score: 0.4074\n",
      "(18, 'f1 test score:', 0.090909094)\n",
      "Train Confusion Matrix:\n",
      "[[10061     0]\n",
      " [  200     0]]\n",
      "Test Confusion Matrix:\n",
      "[[5404    2]\n",
      " [  93    7]]\n",
      "(19, 'f1 test score:', 0.22400001)\n",
      "Train Confusion Matrix:\n",
      "[[10061     0]\n",
      " [  200     0]]\n",
      "Test Confusion Matrix:\n",
      "[[5398    8]\n",
      " [  89   11]]\n",
      "(20, 'f1 test score:', 0.42735043)\n",
      "Train Confusion Matrix:\n",
      "[[10048    13]\n",
      " [  163    37]]\n",
      "Test Confusion Matrix:\n",
      "[[5319   87]\n",
      " [  50   50]]\n",
      "Saved new best model with f1 score: 0.4274\n",
      "(21, 'f1 test score:', 0.33160624)\n",
      "Train Confusion Matrix:\n",
      "[[10061     0]\n",
      " [  185    15]]\n",
      "Test Confusion Matrix:\n",
      "[[5332   74]\n",
      " [  65   35]]\n",
      "(22, 'f1 test score:', 0.30973449)\n",
      "Train Confusion Matrix:\n",
      "[[10061     0]\n",
      " [  190    10]]\n",
      "Test Confusion Matrix:\n",
      "[[5320   86]\n",
      " [  64   36]]\n",
      "(23, 'f1 test score:', 0.32456142)\n",
      "Train Confusion Matrix:\n",
      "[[10060     1]\n",
      " [  180    20]]\n",
      "Test Confusion Matrix:\n",
      "[[5319   87]\n",
      " [  64   36]]\n",
      "(24, 'f1 test score:', 0.35627532)\n",
      "Train Confusion Matrix:\n",
      "[[10058     3]\n",
      " [  122    78]]\n",
      "Test Confusion Matrix:\n",
      "[[5291  115]\n",
      " [  52   48]]\n",
      "(25, 'f1 test score:', 0.57396454)\n",
      "Train Confusion Matrix:\n",
      "[[9892  169]\n",
      " [  51  149]]\n",
      "Test Confusion Matrix:\n",
      "[[5259  147]\n",
      " [   7   93]]\n",
      "Saved new best model with f1 score: 0.5740\n",
      "(26, 'f1 test score:', 0.42487043)\n",
      "Train Confusion Matrix:\n",
      "[[10051    10]\n",
      " [  152    48]]\n",
      "Test Confusion Matrix:\n",
      "[[5353   53]\n",
      " [  59   41]]\n",
      "(27, 'f1 test score:', 0.32941177)\n",
      "Train Confusion Matrix:\n",
      "[[10061     0]\n",
      " [  193     7]]\n",
      "Test Confusion Matrix:\n",
      "[[5363   43]\n",
      " [  75   25]]\n",
      "(28, 'f1 test score:', 0.3425926)\n",
      "Train Confusion Matrix:\n",
      "[[10060     1]\n",
      " [  156    44]]\n",
      "Test Confusion Matrix:\n",
      "[[5323   83]\n",
      " [  58   42]]\n",
      "(29, 'f1 test score:', 0.42105263)\n",
      "Train Confusion Matrix:\n",
      "[[10055     6]\n",
      " [   69   131]]\n",
      "Test Confusion Matrix:\n",
      "[[5290  116]\n",
      " [  42   58]]\n",
      "(30, 'f1 test score:', 0.49844238)\n",
      "Train Confusion Matrix:\n",
      "[[10047    14]\n",
      " [   66   134]]\n",
      "Test Confusion Matrix:\n",
      "[[5261  145]\n",
      " [  17   83]]\n",
      "(31, 'f1 test score:', 0.56886232)\n",
      "Train Confusion Matrix:\n",
      "[[9949  112]\n",
      " [  52  148]]\n",
      "Test Confusion Matrix:\n",
      "[[5253  153]\n",
      " [   8   92]]\n",
      "(32, 'f1 test score:', 0.41750842)\n",
      "Train Confusion Matrix:\n",
      "[[10061     0]\n",
      " [  151    49]]\n",
      "Test Confusion Matrix:\n",
      "[[5275  131]\n",
      " [  38   62]]\n",
      "(33, 'f1 test score:', 0.37878788)\n",
      "Train Confusion Matrix:\n",
      "[[10061     0]\n",
      " [  120    80]]\n",
      "Test Confusion Matrix:\n",
      "[[5288  118]\n",
      " [  47   53]]\n",
      "(34, 'f1 test score:', 0.40425533)\n",
      "Train Confusion Matrix:\n",
      "[[10060     1]\n",
      " [   57   143]]\n",
      "Test Confusion Matrix:\n",
      "[[5277  129]\n",
      " [  44   56]]\n",
      "(35, 'f1 test score:', 0.42033899)\n",
      "Train Confusion Matrix:\n",
      "[[10059     2]\n",
      " [   32   168]]\n",
      "Test Confusion Matrix:\n",
      "[[5271  135]\n",
      " [  33   67]]\n",
      "(36, 'f1 test score:', 0.5229885)\n",
      "Train Confusion Matrix:\n",
      "[[10060     1]\n",
      " [   28   172]]\n",
      "Test Confusion Matrix:\n",
      "[[5245  161]\n",
      " [  11   89]]\n",
      "(37, 'f1 test score:', 0.47826087)\n",
      "Train Confusion Matrix:\n",
      "[[10054     7]\n",
      " [  140    60]]\n",
      "Test Confusion Matrix:\n",
      "[[5190  216]\n",
      " [   1   99]]\n",
      "(38, 'f1 test score:', 0.51200002)\n",
      "Train Confusion Matrix:\n",
      "[[10061     0]\n",
      " [  150    50]]\n",
      "Test Confusion Matrix:\n",
      "[[5219  187]\n",
      " [   3   97]]\n",
      "(39, 'f1 test score:', 0.52631581)\n",
      "Train Confusion Matrix:\n",
      "[[10061     0]\n",
      " [  158    42]]\n",
      "Test Confusion Matrix:\n",
      "[[5285  121]\n",
      " [  25   75]]\n",
      "(40, 'f1 test score:', 0.5529412)\n",
      "Train Confusion Matrix:\n",
      "[[10060     1]\n",
      " [   49   151]]\n",
      "Test Confusion Matrix:\n",
      "[[5255  151]\n",
      " [   8   92]]\n",
      "(41, 'f1 test score:', 0.51704544)\n",
      "Train Confusion Matrix:\n",
      "[[10061     0]\n",
      " [   31   169]]\n",
      "Test Confusion Matrix:\n",
      "[[5255  151]\n",
      " [   9   91]]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 120\n",
    "batch_size = 154\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "run_dir = \"kws-{}\".format(n_epochs)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    best_f1 = -1\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        current_batch = 0\n",
    "        for iteration in range(X_train.shape[0] // batch_size):\n",
    "            current_batch, X_batch, y_batch = next_batch(X_train, y_train, current_batch, batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "\n",
    "        # Compute epoch metrics of interest to display in Tensorboard\n",
    "        summary_train = sess.run(merged, {X: X_train, y: y_train})\n",
    "        file_writer_train.add_summary(summary_train,epoch)\n",
    "        file_writer_train.flush()\n",
    "        \n",
    "        summary_test = sess.run(merged, {X: X_test, y: y_test})\n",
    "        file_writer_test.add_summary(summary_test,epoch)\n",
    "        file_writer_test.flush()   \n",
    "        \n",
    "        # Compute epoch metrics of interest to print in this notebook \n",
    "        pred_train = predicted.eval(feed_dict={X: X_train, y: y_train})\n",
    "        pred_test = predicted.eval(feed_dict={X: X_test, y: y_test})\n",
    "        \n",
    "        logits_train_vals = logits.eval(feed_dict={X: X_train, y: y_train})\n",
    "        logits_test_vals = logits.eval(feed_dict={X: X_test, y: y_test})\n",
    "        confusion_train = confusion.eval(feed_dict={logits: logits_train_vals, y: y_train})\n",
    "        confusion_test = confusion.eval(feed_dict={logits: logits_test_vals, y: y_test})\n",
    "        \n",
    "        tp_val_test = tp.eval(feed_dict={predicted:pred_test, actual:y_test})\n",
    "        tn_val_test = tn.eval(feed_dict={predicted:pred_test, actual:y_test})\n",
    "        fp_val_test = fp.eval(feed_dict={predicted:pred_test, actual:y_test})\n",
    "        fn_val_test = fn.eval(feed_dict={predicted:pred_test, actual:y_test})\n",
    "        prec_val_test = precision.eval(feed_dict={tp:tp_val_test,fp:fp_val_test})\n",
    "        rec_val_test = recall.eval(feed_dict={tp:tp_val_test,fn:fn_val_test})\n",
    "        f1_score_test = f1.eval(feed_dict={precision:prec_val_test, recall:rec_val_test})\n",
    "              \n",
    "        print(epoch, \"f1 test score:\",f1_score_test)\n",
    "        print(\"Train Confusion Matrix:\")\n",
    "        print(confusion_train)\n",
    "        print(\"Test Confusion Matrix:\")\n",
    "        print(confusion_test)\n",
    "\n",
    "        # Save best model so far\n",
    "        model_dir = './{}'.format(run_dir)\n",
    "        makedirs(model_dir)\n",
    "\n",
    "        if f1_score_test > 0 and f1_score_test >= best_f1:\n",
    "            now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "            fname = './{}/kws_model-{}-{}.ckpt'.format(run_dir,epoch,now)\n",
    "            save_path = saver.save(sess, fname)\n",
    "            best_f1 = f1_score_test\n",
    "            print(\"Saved new best model with f1 score: %0.4f\"%f1_score_test)\n",
    "            \n",
    "    file_writer_train.close()\n",
    "    file_writer_test.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Debugging\n",
    "The following cell provides debug information from the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "```\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    logits_vals = logits.eval(feed_dict={X:X_train[4500:4600],y:y_train[4500:4600]})\n",
    "    y_vals = y.eval(feed_dict={y: y_train[4500:4600]})\n",
    "    pred = predicted.eval(feed_dict={X:X_train[4500:4600],y:y_train[4500:4600]})\n",
    "    tp_val = tp.eval(feed_dict={predicted:pred, actual:y_vals})\n",
    "    tn_val = tn.eval(feed_dict={predicted:pred, actual:y_vals})\n",
    "    fp_val = fp.eval(feed_dict={predicted:pred, actual:y_vals})\n",
    "    fn_val = fn.eval(feed_dict={predicted:pred, actual:y_vals})\n",
    "    confus = confusion.eval(feed_dict={logits:logits_vals, y: y_vals})\n",
    "    prec_val = precision.eval(feed_dict={tp:tp_val,fp:fp_val})\n",
    "    rec_val = recall.eval(feed_dict={tp:tp_val,fn:fn_val})\n",
    "    f1_score = f1.eval(feed_dict={precision:prec_val, recall:rec_val})\n",
    "    print(y_vals)\n",
    "    print(pred)\n",
    "    print(tp_val)\n",
    "    print(tn_val)\n",
    "    print(fp_val)\n",
    "    print(fn_val)\n",
    "    print(confus)\n",
    "    print(prec_val)\n",
    "    print(rec_val)\n",
    "    print(f1_score)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Generate a Prediction from a Saved Model\n",
    "The model is not that great. It seems to detect birds outside more than the target class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# look at an example input\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "mel_directory = r'/Volumes/ThorsHammer/DataScience/data/audio-recognition/mel_3.5/'\n",
    "\n",
    "# Learned Parameters from the training dataset\n",
    "# mean= -26.215140\n",
    "# std= 11.788497\n",
    "\n",
    "mean = -31.797126\n",
    "std = 14.150785\n",
    "\n",
    "X_test = np.load(os.path.join(mel_directory,\"161225-003.wav-mel.npy\")).astype(float).transpose(0,2,1)\n",
    "y_test = np.load(os.path.join(mel_directory,\"161225-003-mel-labels.npy\")).astype(int)\n",
    "X_test = normalize_with_paras(X_test, mean, std)\n",
    "\n",
    "# known positive class frame\n",
    "i = 0\n",
    "num = len(X_test)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, r\"./saved models/second/my_model_final.ckpt\")\n",
    "    X_raw = X_test[i:i+num].reshape(num,n_steps,n_inputs)\n",
    "    X_feed = normalize_with_paras(X_raw, mean, std).astype('float32') # calculated above\n",
    "    pred = predicted.eval(feed_dict={X:X_feed})\n",
    "    print('prediction:',pred)\n",
    "    print(sum(pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "idx = np.where(pred > 0)[0]\n",
    "for i in idx:\n",
    "    fig, ax = plt.subplots(figsize=(3, 4))\n",
    "    ax.imshow(X_test[i], cmap=plt.cm.magma, interpolation='nearest', aspect='auto')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print('Label:',y_test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# TODOs\n",
    "* Hyper parameter tuning\n",
    "* More test data\n",
    "* Augment data with copies of beeps"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
