{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##### Mel Spectrograms\n",
    "The purpose of this notebook is to explore the audio data files using Mel Spectrograms. In my previous effort I have used discrete FFT analysis as training data.\n",
    "\n",
    "This work was inspired by Sercan Ö. Arık and Markus Kliegl et al (2017), \"Convolutional Recurrent Neural Networks for Small-Footprint Keyword Spotting\", *Baidu Silicon Valley Artificial IntelligenceLab,1195 Bordeaux Dr. Sunnyvale, CA 94089*\n",
    "\n",
    "The training and test data is prepared using the method described in the above paper. 40 channel Mel Spectrograms of the 16kHz mono audio files are produced using a 100ms sliding window of size three and a half(3.5) seconds. In addition, the mel spectrogram is constrained to the frequency range of interest which is above 200 Hz and below 8kHz.\n",
    "\n",
    "The data for each Mel Spectrogram is saved, un-rolled, as a csv row in an ouput file. The file name prefix is the source audio file name. The resulting files are very large, in the order of 10s of GBytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "source_directory = r'/Volumes/ThorsHammer/DataScience/data/audio-recognition/16k'\n",
    "destination_directory = r'/Volumes/ThorsHammer/DataScience/data/audio-recognition/mel_3.5_100ms/'\n",
    "\n",
    "stride = 0.1\n",
    "sample_length = 3.5 #seconds\n",
    "sample_rate = 16000\n",
    "\n",
    "# This following represent the first postive class observation in the data\n",
    "positive_classes = {\n",
    "    '161225-001' : [9541250], # Large file takes too long for me to wait.\n",
    "    '161225-002' : [713600],\n",
    "    '161225-003' : [813800],\n",
    "    '161225-004' : [808700],\n",
    "    '161225-005' : [686400],\n",
    "    '161225-006' : [201850,1156480,2110750]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161225-000.wav\n",
      "161225-001.wav\n",
      "161225-002.wav\n",
      "161225-003.wav\n",
      "161225-004.wav\n",
      "161225-005.wav\n",
      "161225-006.wav\n"
     ]
    }
   ],
   "source": [
    "# Find the audio wav files in the source folder\n",
    "raw_files = []\n",
    "for file in os.listdir(source_directory):\n",
    "    if file.endswith(\".wav\"):\n",
    "        raw_files.append(file)\n",
    "        print(raw_files[-1])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# prepare the destination directory if not already available\n",
    "if not os.path.exists(destination_directory):\n",
    "    os.makedirs(destination_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Calculate the mel spectrograms for the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def calc_mel(x, sr, hop_length):\n",
    "    S = librosa.feature.melspectrogram(x, sr=sr, n_mels=40, fmin=200, fmax=8000, hop_length=hop_length)\n",
    "    # Convert to log scale (dB) using peak power as reference.\n",
    "    log_S = librosa.power_to_db(S, ref=np.max)\n",
    "    return log_S\n",
    "\n",
    "def load_file(filename, sample_rate = 16000):\n",
    "    data, sample_rate = librosa.load(filename, sr=sample_rate)\n",
    "    return (data, sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def plot_mel(data, hop_length):\n",
    "    librosa.display.specshow(data, x_axis='time', sr=sample_rate, y_axis='mel', hop_length=hop_length)\n",
    "\n",
    "    # Put a descriptive title on the plot\n",
    "    plt.title('mel power spectrogram')\n",
    "\n",
    "    # draw a color bar\n",
    "    plt.colorbar(format='%+02.0f dB')\n",
    "\n",
    "    # Make the figure layout compact\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def save_mel_data(prefix, data):\n",
    "    '''\n",
    "    Save mel data to disk. Input data is an array of mel 2d matrices.\n",
    "    Each matrix has dimensions 40 x 401 (there are 40 mel channels for a 3.5 sec sample).\n",
    "    '''\n",
    "    data = np.asarray(data)\n",
    "    print('Saving mel data: %s'%prefix)\n",
    "    print(data.shape)\n",
    "    \n",
    "    output_file = '{0}{1}-mel.npy'.format(destination_directory,prefix)\n",
    "    np.save(output_file, data)\n",
    "    print('Done: %s'%output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161225-000.wav\n",
      "Saving mel data: 161225-000.wav\n",
      "(3909, 40, 36)\n",
      "Done: /Volumes/ThorsHammer/DataScience/data/audio-recognition/mel_3.5_100ms/161225-000.wav-mel.npy\n",
      "161225-001.wav\n",
      "Saving mel data: 161225-001.wav\n",
      "(6059, 40, 36)\n",
      "Done: /Volumes/ThorsHammer/DataScience/data/audio-recognition/mel_3.5_100ms/161225-001.wav-mel.npy\n",
      "161225-002.wav\n",
      "Saving mel data: 161225-002.wav\n",
      "(480, 40, 36)\n",
      "Done: /Volumes/ThorsHammer/DataScience/data/audio-recognition/mel_3.5_100ms/161225-002.wav-mel.npy\n",
      "161225-003.wav\n",
      "Saving mel data: 161225-003.wav\n",
      "(551, 40, 36)\n",
      "Done: /Volumes/ThorsHammer/DataScience/data/audio-recognition/mel_3.5_100ms/161225-003.wav-mel.npy\n",
      "161225-004.wav\n",
      "Saving mel data: 161225-004.wav\n",
      "(547, 40, 36)\n",
      "Done: /Volumes/ThorsHammer/DataScience/data/audio-recognition/mel_3.5_100ms/161225-004.wav-mel.npy\n",
      "161225-005.wav\n",
      "Saving mel data: 161225-005.wav\n",
      "(474, 40, 36)\n",
      "Done: /Volumes/ThorsHammer/DataScience/data/audio-recognition/mel_3.5_100ms/161225-005.wav-mel.npy\n",
      "161225-006.wav\n",
      "Saving mel data: 161225-006.wav\n",
      "(1544, 40, 36)\n",
      "Done: /Volumes/ThorsHammer/DataScience/data/audio-recognition/mel_3.5_100ms/161225-006.wav-mel.npy\n",
      "CPU times: user 36.2 s, sys: 525 ms, total: 36.8 s\n",
      "Wall time: 36.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for filename in raw_files:\n",
    "    print(filename)\n",
    "    mel = []\n",
    "    data, sample_rate = load_file(os.path.join(source_directory, filename))\n",
    "    hop_length = int(sample_rate*stride)\n",
    "    # perform mel calculation for each sliding window\n",
    "    for i in np.arange(0,len(data)-(int(sample_length*sample_rate)),(int(stride*sample_rate))):\n",
    "        offset = i\n",
    "        x = data[offset:offset+(int(sample_length*sample_rate))]\n",
    "        log_S = calc_mel(x, sample_rate, hop_length=hop_length)\n",
    "        mel.append(log_S)\n",
    "\n",
    "    save_mel_data(filename, mel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Create Labels for the Audio Sequences\n",
    "The purpose of this section is to generate the target labels for supervised training. This is somewhat manual and the following procedure was used:\n",
    " - open an audio file in [Audacity](http://www.audacityteam.org)\n",
    " - by visual inspection of the waveform locate the start and end samples of the target sequence (verify selection by playing the audio in that range)\n",
    " - using a window of 3.45 seconds (the width of the target sequence in this case) label the time-correlated mel spectrograph observation as class 1, otherwise class 0.\n",
    "\n",
    "The audio file contents are as follows:\n",
    "\n",
    "** Washing Machine **\n",
    "``` \n",
    "File :161225-000\n",
    "Beep Sequence Count: 0\n",
    "\n",
    "File :161225-001\n",
    "Beep Sequence Count: 1\n",
    "Start Sample: 9541250\n",
    "End Sample:  9596500\n",
    "\n",
    "File :161225-002\n",
    "Beep Sequence Count: 1\n",
    "Start Sample: 713600\n",
    "End Sample:  721360\n",
    "\n",
    "File :161225-003\n",
    "Beep Sequence Count: 1\n",
    "Start Sample: 813800\n",
    "End Sample:  869300\n",
    "\n",
    "File :161225-004\n",
    "Beep Sequence Count: 1\n",
    "Start Sample: 808700\n",
    "End Sample:  864000\n",
    "\n",
    "File :161225-005\n",
    "Beep Sequence Count: 1\n",
    "Start Sample: 686400\n",
    "End Sample:  742000\n",
    "```\n",
    "** Dryer **\n",
    "```\n",
    "File :161225-006\n",
    "Beep Sequence Count: 3\n",
    "Start Sample: 201850\n",
    "End Sample: 262330\n",
    "Start Sample: 1156480\n",
    "End Sample:  1212300\n",
    "Start Sample: 2110750\n",
    "End Sample:  2118300\n",
    "```\n",
    "\n",
    "Based on this data we will create the label vector for each mel spectrogram row. \n",
    "\n",
    "**Note:** we need to take into account the sliding 4 second windows with a stride of 10ms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Determine the observation index for a given sample numer\n",
    "def calc_mel_observation_index(raw_sample_number):\n",
    "    observation_index = int(raw_sample_number / (sample_rate * stride))\n",
    "    return observation_index\n",
    "\n",
    "def file_len(filename):\n",
    "    f = np.load(filename)\n",
    "    return f.shape[0]\n",
    "\n",
    "def list_all_files(source_directory, truncate_extension=False, extension='.wav'):\n",
    "    # Find the audio wav files in the source folder\n",
    "    raw_files = []\n",
    "    for file in os.listdir(source_directory):\n",
    "        if file.endswith(extension):\n",
    "            if(truncate_extension):\n",
    "                file = file[:file.rfind('.')]\n",
    "            raw_files.append(file)\n",
    "            #print(raw_files[-1])\n",
    "            \n",
    "    return raw_files\n",
    "\n",
    "def save_labels(destination_directory, prefix, labels):\n",
    "    output_file = '{0}{1}-mel-labels'.format(destination_directory,prefix)\n",
    "    np.save(output_file,labels)\n",
    "    print('Done: %s'%output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161225-000 target absent\n",
      "Done: /Volumes/ThorsHammer/DataScience/data/audio-recognition/mel_3.5_100ms/161225-000-mel-labels\n",
      "161225-001 contains target\n",
      "Done: /Volumes/ThorsHammer/DataScience/data/audio-recognition/mel_3.5_100ms/161225-001-mel-labels\n",
      "161225-002 contains target\n",
      "Done: /Volumes/ThorsHammer/DataScience/data/audio-recognition/mel_3.5_100ms/161225-002-mel-labels\n",
      "161225-003 contains target\n",
      "Done: /Volumes/ThorsHammer/DataScience/data/audio-recognition/mel_3.5_100ms/161225-003-mel-labels\n",
      "161225-004 contains target\n",
      "Done: /Volumes/ThorsHammer/DataScience/data/audio-recognition/mel_3.5_100ms/161225-004-mel-labels\n",
      "161225-005 contains target\n",
      "Done: /Volumes/ThorsHammer/DataScience/data/audio-recognition/mel_3.5_100ms/161225-005-mel-labels\n",
      "161225-006 contains target\n",
      "Done: /Volumes/ThorsHammer/DataScience/data/audio-recognition/mel_3.5_100ms/161225-006-mel-labels\n",
      "{'161225-000': 3909, '161225-001': 6059, '161225-002': 480, '161225-003': 551, '161225-004': 547, '161225-005': 474, '161225-006': 1544}\n",
      "CPU times: user 8.93 ms, sys: 49.2 ms, total: 58.1 ms\n",
      "Wall time: 52 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "file_sufix = '.wav-mel.npy'\n",
    "all_files = list_all_files(source_directory, truncate_extension=True)\n",
    "file_len_dict = {}\n",
    "file_label_dict = {}\n",
    "\n",
    "for file in sorted(all_files):\n",
    "    \n",
    "    filename = os.path.join(destination_directory,file+file_sufix)\n",
    "    num_observations = file_len(filename)\n",
    "    file_len_dict[file] = num_observations\n",
    "\n",
    "    labels = np.zeros(num_observations)\n",
    "    \n",
    "    if(file in positive_classes.keys()):\n",
    "        print('%s contains target'%file)\n",
    "        start_sample_array = positive_classes[file]\n",
    "        for start_sample in start_sample_array:        \n",
    "            target_class_range_start = calc_mel_observation_index(start_sample - (sample_rate * 0.5))\n",
    "            target_class_range_end = calc_mel_observation_index(start_sample + (sample_rate * 0.5))\n",
    "            labels[target_class_range_start:target_class_range_end] = 1\n",
    "        file_label_dict[file] = labels\n",
    "    else:\n",
    "        print('%s target absent'%file)\n",
    "    save_labels(destination_directory, file, labels)\n",
    "\n",
    "print (file_len_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(file_label_dict['161225-006'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python ([tensorflow])",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
