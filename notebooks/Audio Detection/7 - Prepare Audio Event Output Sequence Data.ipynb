{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Event Recognition Using Deep Learning (CNN)\n",
    "\n",
    "The subject Audio Event is a laundry appliance end-of-cycle beep sequence. Audio recordings were made of the appliance in operation including the beep sequence. Most of the recording was of the machine performing its normal function as well as \"room tone\". Room tone includes other household and environmental sounds picked up by the recorder.\n",
    "\n",
    "The purpose of training a model in this notebook is to detect the beep itself and not the time sequence of beeps. That will be looked at in subsequent notebooks.\n",
    "\n",
    "Audio data has been prepared in other notebooks for use in this machine learning training.\n",
    "\n",
    "The audio recordings were resampled to 16kHz, amplitude normalised to within +/- 1.0 peak, divided into one minute segments and a discrete Fast Fourier Transform (FFT) analysis was performed. A sliding window of 150ms was used for FFT observation with a stride of 5ms.\n",
    "\n",
    "This resulted in each observation comprising 2400 features which represent the frequency power level (dB) between 0 and 8kHz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data File Setup\n",
    "Configure the folder settings and helper function for loading data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressed FFT Files:\n",
      "['161225-000_16bit-part-0.wav-fft.csv.gz'\n",
      " '161225-000_16bit-part-1.wav-fft.csv.gz'\n",
      " '161225-000_16bit-part-2.wav-fft.csv.gz'\n",
      " '161225-000_16bit-part-3.wav-fft.csv.gz'\n",
      " '161225-000_16bit-part-4.wav-fft.csv.gz'\n",
      " '161225-000_16bit-part-5.wav-fft.csv.gz'\n",
      " '161225-000_16bit-part-6.wav-fft.csv.gz'\n",
      " '161225-001_16bit-part-0.wav-fft.csv.gz'\n",
      " '161225-001_16bit-part-1.wav-fft.csv.gz'\n",
      " '161225-001_16bit-part-10.wav-fft.csv.gz'\n",
      " '161225-001_16bit-part-2.wav-fft.csv.gz'\n",
      " '161225-001_16bit-part-3.wav-fft.csv.gz'\n",
      " '161225-001_16bit-part-4.wav-fft.csv.gz'\n",
      " '161225-001_16bit-part-5.wav-fft.csv.gz'\n",
      " '161225-001_16bit-part-6.wav-fft.csv.gz'\n",
      " '161225-001_16bit-part-7.wav-fft.csv.gz'\n",
      " '161225-001_16bit-part-8.wav-fft.csv.gz'\n",
      " '161225-001_16bit-part-9.wav-fft.csv.gz'\n",
      " '161225-002_16bit-part-0.wav-fft.csv.gz'\n",
      " '161225-003_16bit-part-0.wav-fft.csv.gz'\n",
      " '161225-004_16bit-part-0.wav-fft.csv.gz'\n",
      " '161225-005_16bit-part-0.wav-fft.csv.gz'\n",
      " '161225-006_16bit-part-0.wav-fft.csv.gz'\n",
      " '161225-006_16bit-part-1.wav-fft.csv.gz'\n",
      " '161225-006_16bit-part-2.wav-fft.csv.gz']\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from os.path import isfile, join\n",
    "\n",
    "wav_directory = r'/Volumes/ThorsHammer/Data Science/data/audio-recognition/parts/'\n",
    "fft_directory = r'/Volumes/ThorsHammer/Data Science/data/audio-recognition/fft/'\n",
    "audio_detect_pred_directory = r'/Volumes/ThorsHammer/Data Science/data/audio-recognition/audio-detect-pred/'\n",
    "\n",
    "def list_files(base_dir, ext):\n",
    "    onlyfiles = [f for f in os.listdir(base_dir) if isfile(join(base_dir, f)) and f.split('.')[-1] == ext]\n",
    "    return np.sort(onlyfiles)\n",
    "\n",
    "print('Compressed FFT Files:')\n",
    "fft_compressed_files = list_files(fft_directory,'gz')\n",
    "print(fft_compressed_files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility for Loading a Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "tf.python.control_flow_ops = tf\n",
    "\n",
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "model = load_model('audio_detection.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.models.Sequential at 0x116a74a90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Generate CNN Response from FFT Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11970 test samples\n",
      "11970/11970 [==============================] - 101s   \n",
      "\n",
      "/Volumes/ThorsHammer/Data Science/data/audio-recognition/fft//161225-000_16bit-part-0.wav-fft.csv.gz\n",
      "11970 test samples\n",
      "11970/11970 [==============================] - 100s   \n",
      "\n",
      "/Volumes/ThorsHammer/Data Science/data/audio-recognition/fft//161225-000_16bit-part-1.wav-fft.csv.gz\n",
      "11970 test samples\n",
      "11970/11970 [==============================] - 100s   \n",
      "\n",
      "/Volumes/ThorsHammer/Data Science/data/audio-recognition/fft//161225-000_16bit-part-2.wav-fft.csv.gz\n",
      "11970 test samples\n",
      "11970/11970 [==============================] - 98s    \n",
      "\n",
      "/Volumes/ThorsHammer/Data Science/data/audio-recognition/fft//161225-000_16bit-part-3.wav-fft.csv.gz\n",
      "11970 test samples\n",
      "11970/11970 [==============================] - 99s    \n",
      "\n",
      "/Volumes/ThorsHammer/Data Science/data/audio-recognition/fft//161225-000_16bit-part-4.wav-fft.csv.gz\n",
      "11970 test samples\n",
      "11970/11970 [==============================] - 99s    \n",
      "\n",
      "/Volumes/ThorsHammer/Data Science/data/audio-recognition/fft//161225-000_16bit-part-5.wav-fft.csv.gz\n",
      "6846 test samples\n",
      "6846/6846 [==============================] - 56s    \n",
      "\n",
      "/Volumes/ThorsHammer/Data Science/data/audio-recognition/fft//161225-000_16bit-part-6.wav-fft.csv.gz\n",
      "11970 test samples\n",
      "11970/11970 [==============================] - 108s   \n",
      "\n",
      "/Volumes/ThorsHammer/Data Science/data/audio-recognition/fft//161225-001_16bit-part-0.wav-fft.csv.gz\n",
      "11970 test samples\n",
      "11970/11970 [==============================] - 106s   \n",
      "\n",
      "/Volumes/ThorsHammer/Data Science/data/audio-recognition/fft//161225-001_16bit-part-1.wav-fft.csv.gz\n",
      "1833 test samples\n",
      "1833/1833 [==============================] - 16s    \n",
      "\n",
      "/Volumes/ThorsHammer/Data Science/data/audio-recognition/fft//161225-001_16bit-part-10.wav-fft.csv.gz\n",
      "11970 test samples\n",
      "11970/11970 [==============================] - 103s   \n",
      "\n",
      "/Volumes/ThorsHammer/Data Science/data/audio-recognition/fft//161225-001_16bit-part-2.wav-fft.csv.gz\n",
      "11970 test samples\n",
      "11970/11970 [==============================] - 102s   \n",
      "\n",
      "/Volumes/ThorsHammer/Data Science/data/audio-recognition/fft//161225-001_16bit-part-3.wav-fft.csv.gz\n",
      "11970 test samples\n",
      "11970/11970 [==============================] - 101s   \n",
      "\n",
      "/Volumes/ThorsHammer/Data Science/data/audio-recognition/fft//161225-001_16bit-part-4.wav-fft.csv.gz\n",
      "11970 test samples\n",
      "11970/11970 [==============================] - 101s   \n",
      "\n",
      "/Volumes/ThorsHammer/Data Science/data/audio-recognition/fft//161225-001_16bit-part-5.wav-fft.csv.gz\n",
      "11970 test samples\n",
      "11970/11970 [==============================] - 99s    \n",
      "\n",
      "/Volumes/ThorsHammer/Data Science/data/audio-recognition/fft//161225-001_16bit-part-6.wav-fft.csv.gz\n",
      "11970 test samples\n",
      "11970/11970 [==============================] - 98s    \n",
      "\n",
      "/Volumes/ThorsHammer/Data Science/data/audio-recognition/fft//161225-001_16bit-part-7.wav-fft.csv.gz\n",
      "11970 test samples\n",
      "11970/11970 [==============================] - 99s    \n",
      "\n",
      "/Volumes/ThorsHammer/Data Science/data/audio-recognition/fft//161225-001_16bit-part-8.wav-fft.csv.gz\n",
      "11970 test samples\n",
      "11970/11970 [==============================] - 102s   \n",
      "\n",
      "/Volumes/ThorsHammer/Data Science/data/audio-recognition/fft//161225-001_16bit-part-9.wav-fft.csv.gz\n",
      "10253 test samples\n",
      "10253/10253 [==============================] - 86s    \n",
      "\n",
      "/Volumes/ThorsHammer/Data Science/data/audio-recognition/fft//161225-002_16bit-part-0.wav-fft.csv.gz\n",
      "11681 test samples\n",
      "11681/11681 [==============================] - 99s    \n",
      "\n",
      "/Volumes/ThorsHammer/Data Science/data/audio-recognition/fft//161225-003_16bit-part-0.wav-fft.csv.gz\n",
      "11607 test samples\n",
      "11607/11607 [==============================] - 97s    \n",
      "\n",
      "/Volumes/ThorsHammer/Data Science/data/audio-recognition/fft//161225-004_16bit-part-0.wav-fft.csv.gz\n",
      "10137 test samples\n",
      "10137/10137 [==============================] - 85s    \n",
      "\n",
      "/Volumes/ThorsHammer/Data Science/data/audio-recognition/fft//161225-005_16bit-part-0.wav-fft.csv.gz\n",
      "11970 test samples\n",
      "11970/11970 [==============================] - 100s   \n",
      "\n",
      "/Volumes/ThorsHammer/Data Science/data/audio-recognition/fft//161225-006_16bit-part-0.wav-fft.csv.gz\n",
      "11970 test samples\n",
      "11970/11970 [==============================] - 101s   \n",
      "\n",
      "/Volumes/ThorsHammer/Data Science/data/audio-recognition/fft//161225-006_16bit-part-1.wav-fft.csv.gz\n",
      "7535 test samples\n",
      "7535/7535 [==============================] - 65s    \n",
      "\n",
      "/Volumes/ThorsHammer/Data Science/data/audio-recognition/fft//161225-006_16bit-part-2.wav-fft.csv.gz\n",
      "CPU times: user 5h 42min 9s, sys: 8min 49s, total: 5h 50min 59s\n",
      "Wall time: 44min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from keras import backend as K\n",
    "# input image dimensions\n",
    "sample_length = 2400\n",
    "\n",
    "for item in fft_compressed_files:\n",
    "    pred_file = item[0:item.index('.wav')]\n",
    "    fft_compressed_file = '{0}/{1}'.format(fft_directory,item)\n",
    "    response_output_file = '{0}/{1}.txt'.format(audio_detect_pred_directory,pred_file)\n",
    "\n",
    "    fft_data = pd.read_csv(fft_compressed_file).astype(np.float32)\n",
    "\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        X = fft_data.values.reshape(fft_data.shape[0], 1, sample_length)\n",
    "    else:\n",
    "        X = fft_data.values.reshape(fft_data.shape[0], sample_length, 1)\n",
    "\n",
    "    X = X.astype('float32')\n",
    "\n",
    "    print(X.shape[0], 'test samples')\n",
    "\n",
    "    y_pred = model.predict_classes(X)\n",
    "    print('\\n'+fft_compressed_file)\n",
    "    np.savetxt(response_output_file,y_pred,fmt='%u')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
